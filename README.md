# Silero Streaming TTS with Ollama

This project demonstrates a self-contained setup for streaming text generated by Ollama through Silero TTS for real-time Russian speech synthesis. It ensures that audio is generated only after complete sentences (ending with punctuation) are received, preventing words from being cut off mid-speech.

## Key Features

*   **Punctuation-based Buffering**: Speech synthesis is triggered only upon receiving sentence-ending punctuation marks (e.g., `.`, `?`, `!`, `â€¦`) or at the end of the generation, ensuring natural-sounding speech without mid-word breaks.
*   **Real-time Streaming**: Fetches responses from a local Ollama instance and synthesizes speech on the fly.
*   **Customizable Silero TTS**: Allows configuration of the Silero model, speaker, sample rate, and accentuation options.
*   **Customizable Ollama Integration**: Allows configuration of the Ollama model, base URL, and system prompt.
*   **Markdown/Emoji Cleaning**: Basic text cleaning is performed before speech synthesis.

## Prerequisites

*   Python 3.8+
*   Ollama installed and running. You can start it with `ollama serve &`.
*   PortAudio libraries:
    *   **Linux**: `sudo apt-get install portaudio19-dev libportaudiocpp0 libportaudio2`
    *   **macOS**: `brew install portaudio`
    *   **Windows**: Download from [PortAudio website](http://www.portaudio.com/download.html) and ensure it's in your system's PATH or accessible by Python.

## Installation

1.  Clone the repository (if applicable) or download the files.
2.  Install the required Python packages:

    ```bash
    pip install torch sounddevice requests numpy
    ```

## Usage

1.  Ensure your Ollama server is running (e.g., `ollama serve &`).
2.  Run the main script:

    ```bash
    python streaming_silero.py
    ```
3.  Enter your text prompt when requested.

## Configuration

The main script `streaming_silero.py` loads the Silero TTS model and sets default parameters for both Ollama and Silero. You can modify these defaults directly in the `main()` function within `streaming_silero.py`:

*   **Ollama Model**: `ollama_model` (e.g., `"mistral-small3.1:latest"`, `"llama2:latest"`)
*   **Ollama Base URL**: `ollama_url` (e.g., `"http://localhost:11434"`)
*   **Ollama System Prompt**: `ollama_system_prompt_ru`
*   **Silero Speaker**: `silero_speaker` (e.g., `"baya"`, `"aidar"`, etc. - refer to Silero documentation for available Russian speakers like `v3_1_ru`, `v4_ru`)
*   **Silero Sample Rate**: `silero_sample_rate` (e.g., `24000` or `48000`. Note: `v4_ru` speakers usually support 24kHz or 48kHz, while older models like `v3_1_ru` might require 48kHz. Ensure compatibility with your chosen speaker model.)
*   **Silero Accentuation**: `silero_put_accent` (boolean)
*   **Silero "Yo" Letter**: `silero_put_yo` (boolean)

The core streaming logic is encapsulated in `silero_ollama_stream.py` within the `process_text_to_speech_stream` function, which takes these configurations as arguments.

To use a different Silero model or language, you would need to update the model loading part in `streaming_silero.py`:

```python
# In streaming_silero.py
RU_MODEL, _ = torch.hub.load(
    "snakers4/silero-models",
    "silero_tts",
    language="ru", # Change for other languages e.g., "en", "es"
    speaker="v4_ru"  # Change for other speakers
)
```

Refer to the [Silero Models GitHub](https://github.com/snakers4/silero-models) for available models, languages, and speakers.